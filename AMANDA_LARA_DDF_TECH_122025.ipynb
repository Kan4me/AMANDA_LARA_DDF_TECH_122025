{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnQ+XlHuW6PtTW9GOUBCyi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kan4me/AMANDA_LARA_DDF_TECH_122025/blob/main/AMANDA_LARA_DDF_TECH_122025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install all packages"
      ],
      "metadata": {
        "id": "VHNRNsJfygqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas great-expectations openai streamlit plotly pyyaml kaggle\n",
        "print(\"‚úÖ Main packages installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4iRv-hMhe3y",
        "outputId": "bfc78e41-7117-4155-ced0-78f51271a67f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Main packages installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configue API Kaggle"
      ],
      "metadata": {
        "id": "SpXew6IZyjrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up Kaggle API using Colab Secrets\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"üîê Setting up Kaggle API from Colab Secrets...\")\n",
        "\n",
        "# Create the .kaggle directory\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Read credentials from Secrets\n",
        "kaggle_username = userdata.get('KAGGLE_USERNAME')\n",
        "kaggle_key = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Create the kaggle.json content\n",
        "kaggle_config = f'{{\"username\":\"{kaggle_username}\",\"key\":\"{kaggle_key}\"}}'\n",
        "\n",
        "# Write the config file\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write(kaggle_config)\n",
        "\n",
        "# Set secure permissions\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "\n",
        "print(\"‚úÖ Kaggle API securely configured from Secrets.\")"
      ],
      "metadata": {
        "id": "U1JCRmbzmTH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08bbbe22-fc7c-431e-de3b-3fe00c1169c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Setting up Kaggle API from Colab Secrets...\n",
            "‚úÖ Kaggle API securely configured from Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion & Exploration"
      ],
      "metadata": {
        "id": "CEwFGvc3ykBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract the dataset\n",
        "!kaggle datasets download -d olistbr/brazilian-ecommerce\n",
        "!unzip -o brazilian-ecommerce.zip -d ./olist_data\n",
        "print(\"üì• Dataset downloaded and extracted.\")"
      ],
      "metadata": {
        "id": "aeHJV7mzpm3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab97e59b-83ab-46a8-9b95-54e07d931515"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "brazilian-ecommerce.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  brazilian-ecommerce.zip\n",
            "  inflating: ./olist_data/olist_customers_dataset.csv  \n",
            "  inflating: ./olist_data/olist_geolocation_dataset.csv  \n",
            "  inflating: ./olist_data/olist_order_items_dataset.csv  \n",
            "  inflating: ./olist_data/olist_order_payments_dataset.csv  \n",
            "  inflating: ./olist_data/olist_order_reviews_dataset.csv  \n",
            "  inflating: ./olist_data/olist_orders_dataset.csv  \n",
            "  inflating: ./olist_data/olist_products_dataset.csv  \n",
            "  inflating: ./olist_data/olist_sellers_dataset.csv  \n",
            "  inflating: ./olist_data/product_category_name_translation.csv  \n",
            "üì• Dataset downloaded and extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and explore the main tables\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load key tables\n",
        "customers = pd.read_csv('./olist_data/olist_customers_dataset.csv')\n",
        "orders = pd.read_csv('./olist_data/olist_orders_dataset.csv')\n",
        "order_items = pd.read_csv('./olist_data/olist_order_items_dataset.csv')\n",
        "products = pd.read_csv('./olist_data/olist_products_dataset.csv')\n",
        "order_reviews = pd.read_csv('./olist_data/olist_order_reviews_dataset.csv')\n",
        "\n",
        "print(\"üìä Dataset Overview:\")\n",
        "print(f\"Customers: {customers.shape}\")\n",
        "print(f\"Orders: {orders.shape}\")\n",
        "print(f\"Order Items: {order_items.shape}\")\n",
        "print(f\"Products: {products.shape}\")\n",
        "print(f\"Order Reviews: {order_reviews.shape}\")\n",
        "print(\"\\nüîç Sample from Orders table:\")\n",
        "print(orders.head())"
      ],
      "metadata": {
        "id": "d3LFR2sCpyRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a9968a-34bf-41b9-d4e5-e7618b4e5c92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Dataset Overview:\n",
            "Customers: (99441, 5)\n",
            "Orders: (99441, 8)\n",
            "Order Items: (112650, 7)\n",
            "Products: (32951, 9)\n",
            "Order Reviews: (99224, 7)\n",
            "\n",
            "üîç Sample from Orders table:\n",
            "                           order_id                       customer_id  \\\n",
            "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
            "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
            "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
            "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
            "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
            "\n",
            "  order_status order_purchase_timestamp    order_approved_at  \\\n",
            "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
            "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
            "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
            "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
            "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
            "\n",
            "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
            "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
            "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
            "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
            "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
            "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
            "\n",
            "  order_estimated_delivery_date  \n",
            "0           2017-10-18 00:00:00  \n",
            "1           2018-08-13 00:00:00  \n",
            "2           2018-09-04 00:00:00  \n",
            "3           2017-12-15 00:00:00  \n",
            "4           2018-02-26 00:00:00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unified dataset for analysis\n",
        "# Merge key tables\n",
        "df_merged = orders.merge(order_items, on='order_id') \\\n",
        "                  .merge(products, on='product_id') \\\n",
        "                  .merge(customers, on='customer_id') \\\n",
        "                  .merge(order_reviews[['order_id', 'review_score']],\n",
        "                         on='order_id',\n",
        "                         how='left')\n",
        "\n",
        "print(\"üîÑ Merged dataset shape:\", df_merged.shape)\n",
        "print(\"üìã Merged columns:\", df_merged.columns.tolist())"
      ],
      "metadata": {
        "id": "d4qL9pFCp3Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba9950b-19c8-416c-8056-686b7babcd19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Merged dataset shape: (113314, 27)\n",
            "üìã Merged columns: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state', 'review_score']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Great Expectations for data validation"
      ],
      "metadata": {
        "id": "bDN4up24ykWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y great_expectations\n",
        "!pip install great_expectations==0.18.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEKLdhd49JW5",
        "outputId": "0fa856b6-8091-4010-ae1f-4ed0ae33aac1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: great-expectations 0.18.12\n",
            "Uninstalling great-expectations-0.18.12:\n",
            "  Successfully uninstalled great-expectations-0.18.12\n",
            "Collecting great_expectations==0.18.12\n",
            "  Using cached great_expectations-0.18.12-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<5.0.0,>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (4.2.2)\n",
            "Requirement already satisfied: Click>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (8.3.1)\n",
            "Requirement already satisfied: colorama>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (0.4.6)\n",
            "Requirement already satisfied: cryptography>=3.2 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (43.0.3)\n",
            "Requirement already satisfied: Ipython>=7.16.3 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (7.7.1)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (3.1.6)\n",
            "Requirement already satisfied: jsonpatch>=1.22 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (1.33)\n",
            "Requirement already satisfied: jsonschema>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (4.25.1)\n",
            "Requirement already satisfied: makefun<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (3.26.2)\n",
            "Requirement already satisfied: mistune>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (3.1.4)\n",
            "Requirement already satisfied: nbformat>=5.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (5.10.4)\n",
            "Requirement already satisfied: notebook>=6.4.10 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (6.5.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (25.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2.12.3)\n",
            "Requirement already satisfied: pyparsing>=2.4 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2021.3 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2025.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2.32.4)\n",
            "Requirement already satisfied: ruamel.yaml<0.17.18,>=0.16 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (0.17.17)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.59.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (4.15.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (5.3.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from great_expectations==0.18.12) (2.1.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from altair<5.0.0,>=4.2.1->great_expectations==0.18.12) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from altair<5.0.0,>=4.2.1->great_expectations==0.18.12) (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.2->great_expectations==0.18.12) (2.0.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from Ipython>=7.16.3->great_expectations==0.18.12) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.5.1->great_expectations==0.18.12) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.5.1->great_expectations==0.18.12) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.5.1->great_expectations==0.18.12) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.5.1->great_expectations==0.18.12) (3.0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.10->great_expectations==0.18.12) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch>=1.22->great_expectations==0.18.12) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.5.1->great_expectations==0.18.12) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.5.1->great_expectations==0.18.12) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.5.1->great_expectations==0.18.12) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.5.1->great_expectations==0.18.12) (0.30.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.0->great_expectations==0.18.12) (2.21.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.0->great_expectations==0.18.12) (5.9.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (6.5.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (26.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (25.1.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (7.4.9)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=6.4.10->great_expectations==0.18.12) (1.3.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->great_expectations==0.18.12) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->great_expectations==0.18.12) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->great_expectations==0.18.12) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->great_expectations==0.18.12) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.1->great_expectations==0.18.12) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->great_expectations==0.18.12) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->great_expectations==0.18.12) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->great_expectations==0.18.12) (2025.11.12)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.2->great_expectations==0.18.12) (2.23)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->great_expectations==0.18.12) (1.8.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->great_expectations==0.18.12) (5.9.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->Ipython>=7.16.3->great_expectations==0.18.12) (0.8.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0->great_expectations==0.18.12) (4.5.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (0.3.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (1.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->Ipython>=7.16.3->great_expectations==0.18.12) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython>=7.16.3->great_expectations==0.18.12) (0.2.14)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=6.4.10->great_expectations==0.18.12) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (2.14.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=6.4.10->great_expectations==0.18.12) (2.8)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (4.12.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.9.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (20.11.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=6.4.10->great_expectations==0.18.12) (1.4.0)\n",
            "Using cached great_expectations-0.18.12-py3-none-any.whl (5.4 MB)\n",
            "Installing collected packages: great_expectations\n",
            "Successfully installed great_expectations-0.18.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import yaml\n",
        "import great_expectations as gx\n",
        "\n",
        "\n",
        "print(\"üß™ Starting Great Expectations Data Quality Check (v0.18.12)...\")\n",
        "\n",
        "# 1. CREATE CONTEXT AND CHECK FOR EXISTING SUITE\n",
        "context = gx.get_context()\n",
        "expectation_suite_name = \"olist_quality_suite\"\n",
        "\n",
        "# Remove the suite if it exists from a previous run (to avoid conflicts)\n",
        "if expectation_suite_name in context.list_expectation_suite_names():\n",
        "    context.delete_expectation_suite(expectation_suite_name)\n",
        "    print(f\"‚ö†Ô∏è  Deleted existing suite: '{expectation_suite_name}'\")\n",
        "\n",
        "# Create a fresh expectation suite\n",
        "suite = context.add_expectation_suite(expectation_suite_name)\n",
        "print(f\"‚úÖ Created expectation suite: '{expectation_suite_name}'\")\n",
        "\n",
        "# 2. CREATE VALIDATOR USING RuntimeBatchRequest (Correct pattern for v0.18)\n",
        "from great_expectations.core.batch import RuntimeBatchRequest\n",
        "\n",
        "batch_request = RuntimeBatchRequest(\n",
        "    datasource_name=\"my_temp_datasource\",\n",
        "    data_connector_name=\"default_runtime_data_connector\",\n",
        "    data_asset_name=\"merged_orders\",\n",
        "    runtime_parameters={\"batch_data\": df_merged},\n",
        "    batch_identifiers={\"run_id\": \"colab_run_1\"},\n",
        ")\n",
        "\n",
        "# You must add a simple datasource configuration for the runtime batch request to work.\n",
        "# This uses a minimal in-memory Pandas datasource.\n",
        "datasource_config = {\n",
        "    \"name\": \"my_temp_datasource\",\n",
        "    \"class_name\": \"Datasource\",\n",
        "    \"execution_engine\": {\"class_name\": \"PandasExecutionEngine\"},\n",
        "    \"data_connectors\": {\n",
        "        \"default_runtime_data_connector\": {\n",
        "            \"class_name\": \"RuntimeDataConnector\",\n",
        "            \"batch_identifiers\": [\"run_id\"],\n",
        "        }\n",
        "    },\n",
        "}\n",
        "context.add_datasource(**datasource_config)\n",
        "print(\"‚úÖ Added temporary in-memory datasource.\")\n",
        "\n",
        "# Get the validator\n",
        "validator = context.get_validator(\n",
        "    batch_request=batch_request,\n",
        "    expectation_suite_name=expectation_suite_name,\n",
        ")\n",
        "\n",
        "# 3. ADD YOUR EXPECTATIONS (Data Quality Rules)\n",
        "print(\"üìù Adding data quality expectations...\")\n",
        "validator.expect_column_values_to_not_be_null(column=\"order_id\")\n",
        "validator.expect_column_values_to_be_unique(column=\"order_id\")\n",
        "validator.expect_column_values_to_be_between(\n",
        "    column=\"price\",\n",
        "    min_value=0.01,\n",
        "    max_value=10000\n",
        ")\n",
        "validator.expect_column_values_to_be_in_set(\n",
        "    column=\"order_status\",\n",
        "    value_set=[\"delivered\", \"shipped\", \"canceled\", \"unavailable\", \"processing\", \"invoiced\"]\n",
        ")\n",
        "\n",
        "# Save expectations\n",
        "validator.save_expectation_suite(discard_failed_expectations=False)\n",
        "print(\"‚úÖ Expectations saved.\")\n",
        "\n",
        "# 4. CREATE AND RUN A SIMPLE CHECKPOINT\n",
        "checkpoint_config = {\n",
        "    \"name\": \"olist_colab_checkpoint\",\n",
        "    \"config_version\": 1.0,\n",
        "    \"class_name\": \"SimpleCheckpoint\",\n",
        "    \"validations\": [\n",
        "        {\n",
        "            \"batch_request\": batch_request,\n",
        "            \"expectation_suite_name\": expectation_suite_name\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "checkpoint = context.test_yaml_config(yaml.dump(checkpoint_config))\n",
        "results = checkpoint.run()\n",
        "\n",
        "# 5. PROCESS AND DISPLAY RESULTS\n",
        "# Extract results from the slightly different checkpoint result structure\n",
        "run_results = list(results.run_results.values())[0]\n",
        "validation_result = run_results[\"validation_result\"]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA QUALITY REPORT (v0.18.12)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if validation_result[\"success\"]:\n",
        "    print(\"‚úÖ All critical data quality checks passed!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Some checks failed:\")\n",
        "    for result in validation_result[\"results\"]:\n",
        "        if not result[\"success\"]:\n",
        "            col = result[\"expectation_config\"][\"kwargs\"].get(\"column\", \"N/A\")\n",
        "            exp_type = result[\"expectation_config\"][\"expectation_type\"]\n",
        "            # Show a sample of unexpected values if available\n",
        "            unexpected_list = result.get(\"result\", {}).get(\"partial_unexpected_list\", [])\n",
        "            if unexpected_list:\n",
        "                # Format list for display, show max 3 items\n",
        "                display_list = str(unexpected_list[:3])\n",
        "                if len(unexpected_list) > 3:\n",
        "                    display_list = display_list[:-1] + \", ...]\"\n",
        "                print(f\"   ‚Ä¢ Column '{col}' ({exp_type}): e.g., {display_list}\")\n",
        "            else:\n",
        "                print(f\"   ‚Ä¢ Column '{col}': {exp_type}\")\n",
        "\n",
        "# 6. SAVE DETAILED REPORT\n",
        "report_filename = \"data_quality_report_018.json\"\n",
        "with open(report_filename, \"w\") as f:\n",
        "    json.dump(validation_result, f, indent=2)\n",
        "\n",
        "print(f\"\\nüìÑ Detailed report saved to: {report_filename}\")\n",
        "print(f\"‚úÖ Data Quality Check Complete for GX v0.18.12!\")"
      ],
      "metadata": {
        "id": "8cT5u9nitwsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI to analyze product reviews"
      ],
      "metadata": {
        "id": "LgFMoIlHykrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"ü§ñ Starting LLM-based Sentiment Analysis...\")\n",
        "\n",
        "# Securely load OpenAI API key\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "def analyze_review_sentiment(review_text):\n",
        "    \"\"\"Use GPT to analyze sentiment and extract keywords\"\"\"\n",
        "    if not review_text or pd.isna(review_text):\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful data analyst. Always respond with valid JSON.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"Analyze this product review and return JSON with:\n",
        "                1. sentiment (positive/negative/neutral)\n",
        "                2. primary_emotion (one word)\n",
        "                3. keywords (array of 3-5 keywords)\n",
        "                Review: \"{review_text[:500]}\" \"\"\"}\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        result = response.choices[0].message.content\n",
        "        # Clean JSON response\n",
        "        if result.startswith(\"```json\"):\n",
        "            result = result[7:-3]\n",
        "        elif result.startswith(\"```\"):\n",
        "            result = result[3:-3]\n",
        "\n",
        "        return eval(result)  # Convert string to dict\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing review: {e}\")\n",
        "        return None\n",
        "\n",
        "# Sample analysis on a subset\n",
        "print(\"Analyzing sample reviews (first 5)...\")\n",
        "sample_reviews = order_reviews['review_comment_message'].dropna().head(5).tolist()\n",
        "\n",
        "for i, review in enumerate(sample_reviews):\n",
        "    analysis = analyze_review_sentiment(review)\n",
        "    print(f\"\\nReview {i+1}:\")\n",
        "    print(f\"Text: {review[:100]}...\")\n",
        "    print(f\"Analysis: {analysis}\")\n",
        "    time.sleep(0.5)  # Avoid rate limits\n",
        "\n",
        "print(\"\\n‚úÖ Sentiment analysis complete!\")"
      ],
      "metadata": {
        "id": "1rsIeuDGxz_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a comprehensive Streamlit dashboard"
      ],
      "metadata": {
        "id": "SKxekdawyk_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ecommerce_dashboard.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(\n",
        "    page_title=\"Brazilian E-commerce Dashboard\",\n",
        "    page_icon=\"üáßüá∑\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Title\n",
        "st.title(\"üáßüá∑ Brazilian E-commerce Analytics Dashboard\")\n",
        "st.markdown(\"Interactive analysis of Olist's e-commerce data\")\n",
        "\n",
        "# Load data (cached for performance)\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    customers = pd.read_csv('./olist_data/olist_customers_dataset.csv')\n",
        "    orders = pd.read_csv('./olist_data/olist_orders_dataset.csv')\n",
        "    order_items = pd.read_csv('./olist_data/olist_order_items_dataset.csv')\n",
        "    products = pd.read_csv('./olist_data/olist_products_dataset.csv')\n",
        "\n",
        "    # Merge data\n",
        "    df = orders.merge(order_items, on='order_id') \\\n",
        "               .merge(products, on='product_id') \\\n",
        "               .merge(customers, on='customer_id')\n",
        "\n",
        "    # Convert dates\n",
        "    df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
        "    df['order_month'] = df['order_purchase_timestamp'].dt.to_period('M').astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Sidebar filters\n",
        "st.sidebar.header(\"üìä Filters\")\n",
        "date_range = st.sidebar.date_input(\n",
        "    \"Date Range\",\n",
        "    value=[df['order_purchase_timestamp'].min().date(),\n",
        "           df['order_purchase_timestamp'].max().date()]\n",
        ")\n",
        "\n",
        "selected_states = st.sidebar.multiselect(\n",
        "    \"Customer States\",\n",
        "    options=df['customer_state'].unique(),\n",
        "    default=df['customer_state'].unique()[:3]\n",
        ")\n",
        "\n",
        "price_range = st.sidebar.slider(\n",
        "    \"Price Range (R$)\",\n",
        "    float(df['price'].min()),\n",
        "    float(df['price'].max()),\n",
        "    (0.0, 500.0)\n",
        ")\n",
        "\n",
        "# Apply filters\n",
        "filtered_df = df[\n",
        "    (df['order_purchase_timestamp'].dt.date >= date_range[0]) &\n",
        "    (df['order_purchase_timestamp'].dt.date <= date_range[1]) &\n",
        "    (df['customer_state'].isin(selected_states)) &\n",
        "    (df['price'] >= price_range[0]) &\n",
        "    (df['price'] <= price_range[1])\n",
        "]\n",
        "\n",
        "# KPI Metrics\n",
        "st.header(\"üìà Key Performance Indicators\")\n",
        "col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "with col1:\n",
        "    total_orders = filtered_df['order_id'].nunique()\n",
        "    st.metric(\"Total Orders\", f\"{total_orders:,}\")\n",
        "\n",
        "with col2:\n",
        "    total_revenue = filtered_df['price'].sum()\n",
        "    st.metric(\"Total Revenue\", f\"R$ {total_revenue:,.2f}\")\n",
        "\n",
        "with col3:\n",
        "    avg_order_value = filtered_df.groupby('order_id')['price'].sum().mean()\n",
        "    st.metric(\"Avg Order Value\", f\"R$ {avg_order_value:,.2f}\")\n",
        "\n",
        "with col4:\n",
        "    unique_customers = filtered_df['customer_id'].nunique()\n",
        "    st.metric(\"Unique Customers\", f\"{unique_customers:,}\")\n",
        "\n",
        "# Visualizations\n",
        "st.header(\"üìä Sales Analysis\")\n",
        "\n",
        "tab1, tab2, tab3 = st.tabs([\"Trends\", \"Geography\", \"Products\"])\n",
        "\n",
        "with tab1:\n",
        "    # Monthly sales trend\n",
        "    monthly_sales = filtered_df.groupby('order_month').agg({\n",
        "        'order_id': 'nunique',\n",
        "        'price': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    fig_trend = go.Figure()\n",
        "    fig_trend.add_trace(go.Scatter(\n",
        "        x=monthly_sales['order_month'],\n",
        "        y=monthly_sales['price'],\n",
        "        mode='lines+markers',\n",
        "        name='Revenue',\n",
        "        line=dict(color='#FF4B4B')\n",
        "    ))\n",
        "\n",
        "    fig_trend.update_layout(\n",
        "        title=\"Monthly Revenue Trend\",\n",
        "        xaxis_title=\"Month\",\n",
        "        yaxis_title=\"Revenue (R$)\",\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig_trend, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    # Sales by state\n",
        "    state_sales = filtered_df.groupby('customer_state').agg({\n",
        "        'order_id': 'nunique',\n",
        "        'price': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    fig_map = px.bar(\n",
        "        state_sales,\n",
        "        x='customer_state',\n",
        "        y='price',\n",
        "        color='order_id',\n",
        "        title=\"Revenue by Customer State\",\n",
        "        labels={'price': 'Revenue (R$)', 'order_id': 'Number of Orders'},\n",
        "        color_continuous_scale='Viridis'\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig_map, use_container_width=True)\n",
        "\n",
        "with tab3:\n",
        "    # Top products\n",
        "    top_products = filtered_df.groupby('product_category_name').agg({\n",
        "        'order_id': 'nunique',\n",
        "        'price': 'sum'\n",
        "    }).nlargest(10, 'price').reset_index()\n",
        "\n",
        "    fig_products = px.treemap(\n",
        "        top_products,\n",
        "        path=['product_category_name'],\n",
        "        values='price',\n",
        "        color='order_id',\n",
        "        title=\"Top 10 Product Categories by Revenue\",\n",
        "        color_continuous_scale='RdBu'\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig_products, use_container_width=True)\n",
        "\n",
        "# Data preview\n",
        "st.header(\"üîç Filtered Data Preview\")\n",
        "st.dataframe(\n",
        "    filtered_df[[\n",
        "        'order_id', 'order_purchase_timestamp',\n",
        "        'customer_state', 'product_category_name',\n",
        "        'price', 'freight_value'\n",
        "    ]].head(20),\n",
        "    use_container_width=True\n",
        ")\n",
        "\n",
        "# Download button\n",
        "st.sidebar.header(\"üì• Export\")\n",
        "csv = filtered_df.to_csv(index=False)\n",
        "st.sidebar.download_button(\n",
        "    label=\"Download Filtered Data as CSV\",\n",
        "    data=csv,\n",
        "    file_name=\"filtered_ecommerce_data.csv\",\n",
        "    mime=\"text/csv\"\n",
        ")\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.info(\"Dashboard created for Dadosfera Technical Test\")"
      ],
      "metadata": {
        "id": "VAyu7Xc20eEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch the Streamlit app from Colab"
      ],
      "metadata": {
        "id": "RwIFu6bU0lIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üöÄ Launching Streamlit Dashboard...\")\n",
        "print(\"This will generate a public URL. Copy it to access your dashboard.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Run Streamlit in the background\n",
        "get_ipython().system_raw('streamlit run /content/ecommerce_dashboard.py --server.port 8501 --server.enableCORS false &')\n",
        "\n",
        "# Use localtunnel to expose the app\n",
        "!npm install -q localtunnel\n",
        "import time\n",
        "time.sleep(5)  # Wait for Streamlit to start\n",
        "\n",
        "print(\"\\nYour public dashboard URL:\")\n",
        "!npx localtunnel --port 8501 2>&1 | grep -o \"https://[^ ]*\" | head -1"
      ],
      "metadata": {
        "id": "KZCbe1MM0lrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}